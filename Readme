Assignment 3 consists of two parts.
Part one:  autonomous navigation
youtube link is https://www.youtube.com/watch?v=FOefRcGsuhU&t=22s
The code part is based on a turtorial on the following webpage.
https://hotblackrobotics.github.io/en/blog/2018/01/29/seq-goals-py/
Before starting autonomous navigation, I give the initial position 
through rviz by drag and click. Then I use keyboard teleop to let 
turtlebot looking around to get better estimation on its location.
After doing all the above, I start the navigation node and the turtle
visits four corners autonomously.

Part two: voice control 
youtube link is https://www.youtube.com/watch?v=3Umtj2mliDg&t=57s
The code is developed based on the code provided in assignment descripiton.
The original code contains a part which lets turtlebot goes to a
predefined location using keyword "one". Turtlebot will need user to
say "yes" to confirm the action when turtlebot asks for. But this part
of functionality is disabled due to the noisy enviroment and low 
recognation rate at the time of demo.
